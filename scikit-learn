Sure! Here’s the step-by-step guide with all the necessary tools and actions you need for your eye recognition project, ready for you to copy into a PDF for easy reference during your work.


---

Step-by-Step Guide: Eye Recognition System for Niqabi Girls

Day 1: Setting Up and Basic Eye Detection


---

1. Set Up Development Environment

Tools Needed:

Python 3.x (Download from python.org)

VS Code or any text editor (Download from VS Code)

Webcam (Integrated or external)


Actions:

1. Install Python on your computer.


2. Install VS Code or any editor to write Python code.


3. Install necessary libraries to your environment.



Install Libraries: In your command prompt or terminal, type:

pip install opencv-python dlib numpy imutils face_recognition

These libraries are required for detecting faces and eyes, and for basic image processing.


---

2. Collect Eye Images for Training

Actions:

Collect clear and high-quality images of eyes from all team members.

Ensure the images have different lighting conditions and angles to make the model more robust.

Store these images in a folder called eye_images/.



---

3. Implement Basic Eye Detection Using OpenCV/Dlib

Tools Needed:

Dlib and OpenCV for face and eye detection.


Actions:

1. Open the terminal in VS Code and create a new Python file called eye_detection.py.


2. Write code for basic face and eye detection using Dlib:



import cv2
import dlib

# Load Dlib's face detector and facial landmarks predictor
detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')

# Open video capture
cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Detect faces
    faces = detector(gray)
    
    for face in faces:
        landmarks = predictor(gray, face)
        
        # Draw eye regions (landmarks 36-41 for left eye, 42-47 for right eye)
        for i in range(36, 42):
            cv2.circle(frame, (landmarks.part(i).x, landmarks.part(i).y), 2, (0, 255, 0), -1)
        for i in range(42, 48):
            cv2.circle(frame, (landmarks.part(i).x, landmarks.part(i).y), 2, (0, 255, 0), -1)

    cv2.imshow('Eye Recognition', frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

3. Run this code to check if the system detects the eyes correctly from the webcam.




---

4. Preprocess Eye Images

Actions:

Convert the detected eye images into grayscale for better performance.

Resize the images to a standard size (e.g., 100x100 pixels).

Normalize pixel values to values between 0 and 1.


Here’s how you can preprocess the image:

import cv2
import numpy as np

# Example: preprocess eye images
def preprocess_image(image):
    # Convert to grayscale
    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # Resize image
    resized_image = cv2.resize(gray_image, (100, 100))
    
    # Normalize image
    normalized_image = resized_image / 255.0
    
    return normalized_image


---

Day 2: Training and Real-Time Recognition


---

5. Train a Simple Eye Recognition Model

Tools Needed:

Scikit-learn for machine learning model training.


Actions:

1. Collect feature data for the eyes from the preprocessed images. You could use pixel values or the distance between landmarks.


2. Create a training set and labels for each image.


3. Train a classifier like K-Nearest Neighbors (KNN) or Support Vector Machine (SVM).



Here’s how to implement KNN for simple classification:

from sklearn.neighbors import KNeighborsClassifier
import numpy as np

# Example: features and labels (you'll collect these from your images)
X = np.array([eye_features])  # Features extracted from images
y = np.array([labels])  # Labels (user ID or name)

# Train the KNN classifier
model = KNeighborsClassifier(n_neighbors=3)
model.fit(X, y)


---

6. Implement Real-Time Eye Recognition

Actions:

1. Integrate the trained model into real-time webcam input.


2. When the system detects eyes, it should classify them and print the result.



Here's how to implement real-time recognition:

# Test with new data (real-time recognition)
predictions = model.predict(new_eye_data)  # new_eye_data is the preprocessed data from the webcam

# Display result
if predictions:
    print("User Recognized:", predictions[0])
else:
    print("User Not Recognized")


---

7. Testing and Debugging

Actions:

1. Test the model with various eye images to ensure accuracy.


2. Debug any issues such as mismatches in recognition or slow processing.


3. Fine-tune the model if necessary (e.g., improve training data, experiment with different classifiers).




---

Final Integration and GitHub Upload


---

8. Organize Code and Upload to GitHub

Actions:

1. Clean up your code and add comments explaining each part.


2. Create a new repository on GitHub.


3. Initialize your local directory as a Git repository:

git init


4. Add the files:

git add .


5. Commit changes:

git commit -m "Initial commit"


6. Push to GitHub:

git push -u origin main




---

Final Checklist:

Set Up Environment: Python, libraries, VS Code.

Gather Eye Images: Multiple images for each user.

Basic Eye Detection: Implement OpenCV/Dlib for detecting eyes.

Preprocess Images: Convert to grayscale, resize, and normalize.

Train the Model: Use KNN or SVM for eye classification.

Real-Time Recognition: Implement webcam-based real-time recognition.

Testing & Debugging: Ensure everything works as expected.

GitHub Upload: Clean, comment, and push code to GitHub.



---

With this guide, you should be ready to tackle the software part of the project efficiently in two days. Best of luck with your project, and feel free to reach out if you need more help!

